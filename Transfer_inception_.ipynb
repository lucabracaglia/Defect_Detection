{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cf0fbd",
   "metadata": {},
   "source": [
    "# LIBRERIE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f_zuppx2minH",
   "metadata": {
    "id": "f_zuppx2minH"
   },
   "outputs": [],
   "source": [
    "#Importa le librerie necessarie per l'esecuzione del codice\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import keras\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, accuracy_score\n",
    "from skimage import io\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, BatchNormalization, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Sequential,Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed9578",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b229ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "47b229ea",
    "outputId": "1b95a2f8-a829-4acf-8a3a-1243282c1787"
   },
   "outputs": [],
   "source": [
    "# Specifica la directory contenente le immagini da elaborare\n",
    "input_dir = \"images\"\n",
    "# Specifica la directory in cui salvare le immagini elaborate\n",
    "output_dir = \"images/imagesprocess\"\n",
    "\n",
    "# Crea la directory di output se non esiste gi√†\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Cicla attraverso tutte le immagini nella directory di input\n",
    "for filename in os.listdir(input_dir):\n",
    "\n",
    "    #leggo l'immagine\n",
    "    img = cv2.imread(os.path.join(input_dir, filename))\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (224,224))\n",
    "    \n",
    "    # Salva l'immagine elaborata nella directory di output con lo stesso nome dell'immagine originale\n",
    "    cv2.imwrite(os.path.join(output_dir, filename),resized_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df7696",
   "metadata": {},
   "source": [
    "# REALIZZAZIONE FOLD DI TRAINING E DI TEST\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jKSVXMFHWZAF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "jKSVXMFHWZAF",
    "outputId": "1df3b9b7-aed1-44aa-e03a-95d68eb993b9"
   },
   "outputs": [],
   "source": [
    "#Si crea una lista contenente il nome dei file associati alle fold di train\n",
    "training_fold_files = []\n",
    "for file_name in os.listdir(r'bootstrap_folds/train_folds'):\n",
    "    if file_name.endswith('.csv'):\n",
    "        training_fold_files.append(file_name)\n",
    "        \n",
    "#Lista di liste contente il path delle singole immagini per ogni fold di train       \n",
    "Train_image=[]      \n",
    "for fold_n in training_fold_files:\n",
    "    training_immagine_fold_n=[]\n",
    "    with open (f'bootstrap_folds/train_folds/{fold_n}') as csvfile:\n",
    "        reader= csv.reader(csvfile)\n",
    "        for i,row in enumerate(reader):\n",
    "            if i == 0:\n",
    "                continue  # salta la prima riga\n",
    "            training_immagine_fold_n.append(row[1])\n",
    "    Train_image.append(training_immagine_fold_n)\n",
    "\n",
    "\n",
    "#partendo dagli indici contenuti nelle fold andiamo a creare il percorso associato a ciascuna immagine \n",
    "training_files=[]\n",
    "file_path = 'images'\n",
    "file_prefix = 'cell'\n",
    "\n",
    "for fold_row in Train_image:    \n",
    "    training_files_row=[]\n",
    "    for train_image_data in fold_row:\n",
    "        for file_name in os.listdir(file_path):\n",
    "            if file_name.startswith(file_prefix):  \n",
    "                file_number=int(file_name[len(file_prefix):-4])\n",
    "                if file_number == int(train_image_data):\n",
    "                    training_files_row.append(os.path.join(file_path,f'imagesprocess/{file_name}')) \n",
    "    training_files.append(training_files_row)\n",
    "training_files_=[[elem.replace('\\\\','/')for elem in training_files_row]for training_files_row in training_files]\n",
    "\n",
    "\n",
    "#Si definisce il percorso del file CSV contenente le etichette\n",
    "label_file = 'labels.csv'\n",
    "\n",
    "#Si crea il dizionario che associa ogni immagine alla sua etichetta\n",
    "labels_immage = {}\n",
    "with open(label_file) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        img_path, label_str = row[0].split('\\t')\n",
    "        img_path = img_path.replace('/','/imagesprocess/')\n",
    "        label = int(label_str)\n",
    "        labels_immage[img_path] = label\n",
    "\n",
    "\n",
    "#Per ogni fold di training si carica l'immagine e l'etichetta associata seguendo l'indicizzazione delle fold\n",
    "training_images=[]\n",
    "training_labels=[]\n",
    "\n",
    "for fold in training_files_:\n",
    "    training_fold_images=[]\n",
    "    training_fold_labels=[]\n",
    "    for img in fold:\n",
    "        training_fold_images.append(io.imread(f'{img}'))\n",
    "        training_fold_labels.append(labels_immage[img])\n",
    "    training_images.append(training_fold_images)\n",
    "    training_labels.append(training_fold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ghL7mgg1escT",
   "metadata": {
    "id": "ghL7mgg1escT"
   },
   "outputs": [],
   "source": [
    "#Si crea una lista contenente il nome dei file associati alle fold di test\n",
    "testing_fold_files = []\n",
    "for file_name in os.listdir(r'bootstrap_folds/test_folds'):\n",
    "    if file_name.endswith('.csv'):\n",
    "        testing_fold_files.append(file_name)\n",
    "        \n",
    "#Lista di liste contente il path delle singole immagini per ogni fold di tesst\n",
    "Test_image=[] \n",
    "for fold_n in testing_fold_files:\n",
    "    testing_immagine_fold_n=[]\n",
    "    with open (f'bootstrap_folds/test_folds/{fold_n}') as csvfile:\n",
    "        reader= csv.reader(csvfile)\n",
    "        for i,row in enumerate(reader):\n",
    "            if i == 0:\n",
    "                continue  # salta la prima riga\n",
    "            testing_immagine_fold_n.append(row[1])\n",
    "    Test_image.append(testing_immagine_fold_n)          \n",
    "\n",
    "#partendo dagli indici contenuti nelle fold andiamo a creare il percorso associato a ciascuna immagine\n",
    "testing_files=[]\n",
    "file_path = 'images'\n",
    "file_prefix = 'cell'\n",
    "\n",
    "for fold_row in Test_image:    \n",
    "    testing_files_row=[] \n",
    "    for test_image_data in fold_row:\n",
    "        for file_name in os.listdir(file_path):\n",
    "            if file_name.startswith(file_prefix):\n",
    "                file_number=int(file_name[len(file_prefix):-4])\n",
    "                if file_number == int(test_image_data):\n",
    "                    testing_files_row.append(os.path.join(file_path,file_name))       \n",
    "    testing_files.append(testing_files_row)\n",
    "testing_files_=[[elem.replace('\\\\','/')for elem in testing_files_row]for testing_files_row in testing_files]\n",
    "\n",
    "#Per ogni fold di test si carica l'immagine e l'etichetta associata seguendo l'indicizzazione delle fold\n",
    "images_test=[]\n",
    "labels_test=[]\n",
    "\n",
    "for fold in testing_files_:\n",
    "    test_fold_images=[]\n",
    "    test_fold_labels=[]\n",
    "    for img in fold:\n",
    "        img_path = img.replace('images/', 'images/imagesprocess/')\n",
    "        test_fold_images.append(io.imread(f'{img_path}'))\n",
    "        test_fold_labels.append(labels_immage[img_path])\n",
    "    images_test.append(test_fold_images)\n",
    "    labels_test.append(test_fold_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d09d82",
   "metadata": {},
   "source": [
    "# DEFINIZIONE MODELLO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M5ACKIwfgCWc",
   "metadata": {
    "id": "M5ACKIwfgCWc"
   },
   "outputs": [],
   "source": [
    "#Inizializzazione del modello preaddestrato\n",
    "base_model = InceptionV3(weights='imagenet', \n",
    "                                include_top=False, \n",
    "                                input_shape=(224, 224,3))\n",
    "\n",
    "#I parametri dei layer di convoluzione non vengono riaddestrati\n",
    "base_model.trainable = False\n",
    "\n",
    "# Vengono rinizializzati i layer di classificazione in base al task specifico\n",
    "x = base_model.output\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "#for layer in base_model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# Si utilizza il modello appena definito per iniziare l'addestramento\n",
    "model = Model(base_model.input, predictions)\n",
    "model.compile(Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eab5d5",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kUSTdHo-WuiJ",
   "metadata": {
    "id": "kUSTdHo-WuiJ"
   },
   "outputs": [],
   "source": [
    "#Una volta aver definito anche il criterio di early stopping, si addestra il modello per ogni fold di training\n",
    "model_save_dir='Modello'\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "for i,fold in enumerate(training_fold_files):\n",
    "    \n",
    "    clear_session()\n",
    "    print(f\"..... Start {fold} Training....\")\n",
    "    x_train_=np.array(training_images[i])\n",
    "    x_train_ = x_train_/255.0\n",
    "    y_train_ = np.array(training_labels[i])\n",
    "    y_train_ = to_categorical(y_train_)\n",
    "    \n",
    "    #Si salva il migliore modello per ogni fold\n",
    "    checkpoint_filepath = f\"{model_save_dir}/best_model_fold_{i+1}.h5\"\n",
    "    checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                                          monitor='val_loss', \n",
    "                                          mode='min', \n",
    "                                          save_best_only=True, \n",
    "                                          save_weights_only=False)\n",
    "    \n",
    "    history = model.fit(x_train_, y_train_, batch_size=32, epochs=15, callbacks=[early_stopping, checkpoint_callback], validation_split=0.2)\n",
    "    \n",
    "    #Salvo inoltre le prestazioni su loss e accuracy per ogni fold\n",
    "    with open(f'{model_save_dir}/history_train_fold_{i+1}.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c41051",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "b8c41051",
    "outputId": "7cf38d51-5b2c-41d2-e5fe-49fcc64b7750"
   },
   "outputs": [],
   "source": [
    "#Per ogni fold di test vado a plottare i grafici relativi a loss e accuracy (Training e validation)\n",
    "for i,fold in enumerate(training_fold_files):\n",
    "\n",
    "    with open(f'{model_save_dir}/history_train_fold_{i+1}.pkl', 'rb') as f:\n",
    "        graph = pickle.load(f)\n",
    "        \n",
    "    print(f\"GRAPH FOR ACCURACY AND LOSS ON TRAINING AND VALIDATION SET FOLD {i+1}\")\n",
    "\n",
    "    acc = graph['accuracy']\n",
    "    val_acc = graph['val_accuracy']\n",
    "\n",
    "    loss = graph['loss']\n",
    "    val_loss = graph['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')   \n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,1.0])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96a3ff",
   "metadata": {},
   "source": [
    "# TESTING E VALUTAZIONE PERFORMANCE DEL MODELLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdede38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cdede38",
    "outputId": "feea5832-de93-478e-940c-8bf076e87a1c"
   },
   "outputs": [],
   "source": [
    "#Si inizializzano due liste con gli score richiesti (f1_score e accuracy)\n",
    "f_score=[]\n",
    "accuracy=[]\n",
    "\n",
    "#Per ogni fold di test carico il modello addestrato e valuto le prestazioni \n",
    "for i,fold in enumerate(testing_fold_files):\n",
    "    \n",
    "    my_model = keras.models.load_model(f\"{model_save_dir}/best_model_fold_{i+1}.h5\")\n",
    "    \n",
    "    clear_session()\n",
    "    print(f\"..... Start {fold} Testing....\")\n",
    "    x_test_= np.array(images_test[i])\n",
    "    x_test_ = x_test_/255.0\n",
    "    y_test_ = np.array(labels_test[i])\n",
    "    y_test_ = to_categorical(y_test_)\n",
    "    \n",
    "    #Valutazione delle prestazioni del modello\n",
    "    test_eval = my_model.evaluate(x_test_, y_test_, verbose=0)\n",
    "    y_pred = my_model.predict(x_test_)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test_, axis=1) \n",
    "    f1 = f1_score(y_test_classes, y_pred_classes, average=None)\n",
    "    f=np.mean(f1)\n",
    "    acc = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    f_score.append(f)\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "    print('F1 Score:', f)\n",
    "    print('Accuracy:', acc)\n",
    "    print(\"CM:\\n\" + str(confusion_matrix(y_test_classes, y_pred_classes)) + \"\\n\")\n",
    "    print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dalle liste degli score valuto le prestazioni medie su tutte le fold \n",
    "print(sum(f_score)/len(f_score))\n",
    "print(sum(accuracy)/len(accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
